\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\begin{document}
	\title{Introdução à Análise Real}
	\author{Daniel Frederico Lins Leite}
	\date{2015/09/19}
	
	\maketitle
		
	\section{Topologia do Espaço Euclidiano}\label{topologia-do-espaco-euclidiano}
	
	\subsection{O Espaço Euclidiano}\label{o-espaco-euclidiano}
	
	O espaço euclidiano n-dimensional é representado por \(\mathbb{R}^{n}\) e
	é formado por todas as n-tuplas de números reais que são representadas
	por \(x = (x_{1},\ldots,x_{n)}\). Quando se fala do espaço euclidiano
	estas n-tuplas também são chamadas de pontos e/ou vetores.
	
	As seguintes operações entre tuplas são:
	
	Igualdade: $x$ é igual a $y$ se e somente se ($\leftrightarrow $) para todo ($\forall$) i entre 1 e n, $x_i$ é igual a $y_i$.
	\[x = y\  \leftrightarrow \ x_{i} = y_{i}\forall i \in (1\ldots n)\]
	
	Soma:
	\[x + y = (x_{1} + y_{1},\ldots,x_{n} + y_{n})\]
	
	Escala:
	\[\alpha \in R, \alpha x = \left( \alpha x_{1},\ldots,\alpha x_{n} \right)\]
	
	Deste modo:
	
	\[0x = (0x_{1},\ldots,0x_{n})\]
	
	\[0x = x - x = (x_{1} - x_{1},\ldots,x_{n} - x_{n})\]
	
	\[x + y = y + x\]
	
	\[x + 0 = x\]
	
	\[x + \left( y + z \right) = \left( x + y \right) + z\]
	
	\[\alpha ( \beta x) = (\alpha\beta)x\]
	
	\[ (\alpha + \beta)x = \alpha x + \beta x\]
	
	\[\alpha ( x + y ) = \alpha x + \alpha y\]
	
	Deste modo qualquer tupla pode ser escrita na forma:
	
	\[x = x_{1}e_{1} + \ldots + x_{n}e_{n}\]	
	\[e_{i} = \left( x_{j} \right)\ onde\ j\  \in \left\lbrack 1,n \right\rbrack\text{\ e\ }\left\{ \begin{matrix}
	0,\ se\ j\  \neq i \\
	1,\ se\ j = 1 \\
	\end{matrix} \right.\ \]
	
	\subsubsection{Produto Interno}\label{produto-interno}
	
	O espaço euclidiano possui uma operação chamada de produto
	interno:
	
	\[<x,y> = x_{1}y_{1} + \ldots + x_{n}y_{n}\]
	
	\paragraph{Propriedades do Produto
		Interno}\label{propriedades-do-produto-interno}
	
	\[< x,y > = < y,x >\]
	
	\[< x,y + z > \  = \  < x,y > + < x,z >\]
	
	\[< \alpha x,y > = \alpha < x,y >\]
	
	\[< x,x > \  > 0\ se\ x\  \neq 0\]
	
	\paragraph{Provas:}
	\paragraph{Comutatividade}\label{comutatividade}
	\begin{align*}
		< x,y >\\
		&= \ x_{1}y_{1} + \ldots + x_{n}y_{n}\\
		&= y_{1}x_{1} + \ldots + y_{n}x_{n}\\
		&= <y,x>\\
		\blacksquare
	\end{align*}
		
	\paragraph{Distributatividade Vetorial}\label{distributatividade-vetorial}
	\begin{align*}
		<x,y+z>\\
		&= x_{1}\left( y_{1}{+ z}_{1} \right) + \ldots + x_{n}\left( y_{n}{+ z}_{n} \right)\\
		&= x_{1}y_{1}{+ x_{1}z}_{1} + \ldots + x_{n}y_{n}{+ x_{n}z}_{n}\\
		&= x_{1}y_{1} + \ldots + x_{n}y_{n} + x_{1}z_{1} + \ldots + x_{n}z_{n}\\
		&= < x,y > + < x,z >\\
		\blacksquare
	\end{align*}	
	\paragraph{Distrivutatividade Escalar}\label{distrivutatividade-escalar}
	\begin{align*}
		<\alpha x,y>\\
		&= \alpha x_{1}y_{1} + \ldots + \alpha x_{n}y_{n}\\
		&= \alpha\left( x_{1}y_{1} + \ldots + x_{n}y_{n} \right)\\
		&= \alpha < x,y >\\
		\blacksquare
	\end{align*}
	
	\paragraph{Ortogonalidade}\label{ortogonalidade}
	
	\[< x,y > \  = 0\]
	
	Se x e/ou y forem zero, o caso é trivialmente provado. Porém, caso
	
	\[y = z - \frac{< x,z >}{< x,x >}x\]
	
	\[< x,y > \  = \  < x,z - \frac{< x,z >}{< x,x >}x >\]
	
	\[= < x,z > - < x,\frac{< x,z >}{< x,x >}x >\]
	
	\[= < x,z > - \ \frac{< x,z >}{< x,x >} < x,x >\]
	
	\[= < x,z > - \ \frac{< x,z >}{< x,x >} < x,x >\]
	
	\[= < x,z > - < x.z >\]
	
	\[= 0\]
	
	\[\]
	
	Isso significa que toda tupla do espaço euclidiano possui pelo menos uma
	outra tupla que é ortogonal a esta.
	
	Desse modo, z pode ser escrito por:
	
	\[z = y + \frac{< x,z >}{< x,x >}x\]
	
	Isto significa que (y, \(\frac{< x,z >}{< x,x >}x)\) podem descrever
	qualquer vetor do espaço o que os fazem serem a base do espaço. Mais
	sobre bases à seguir.
	
	\subsubsection{Norma}\label{norma}
	
	Sendo \(< x,x >\):
	
	\[< x,x >\]
	
	\[= x_{1}x_{1} + \ldots + x_{n}x_{n}\]
	
	\[= x_{1}^{2} + \ldots + x_{n}^{2}\]
	
	E sendo a fórmula
	
	\[\left| x \right| = \sqrt{x_{1}^{2} + \ldots + x_{n}^{2}}\]
	
	Podemos chamar de ``Norma de X'':
	
	\[\left| x \right| = \sqrt{< x,x >}\]
	
	\[< x,x > \  = \ {|x|}^{2}\]
	
	Mais genericamente, toda função \(\mathbb{R}^{n}\mathbb{\rightarrow R}\)
	pode ser chamada como norma.
	
	Caso a tupla/vetor possua norma 1, se diz que a tupla/vetor está normalizado, que é um(a) tupla/vetor unitário. Pode-se normalizar qualquer tupla/vetor diferente de zero do seguinte modo:
	
	\[u = \frac{x}{|x|}\]
	
	\paragraph{Propriedades da Norma}\label{propriedades-da-norma}
	
	Por esta definição a norma possui as seguintes propriedades
	
	\[\left| x \right| > 0,\ se\ x \neq 0\]
	
	\[\left| \alpha x \right| = \left| \alpha \right||x|\]
	
	\[\left| x + y \right| \leq \left| x \right| + |y|\]
	
	\[\left| \left| x \right| \right| = \left| x \right|\]
	
	Exemplo:
	
	\[a = b - c + d\]
	
	\[\left| a \right| = \left| b - c + d \right|\]
	
	\[\left| a \right| \leq \left| b - c \right| + \left| d \right|\]
	
	\paragraph{Teorema de Pitágoras}\label{teorema-de-pituxe1goras}
	
	Se analisarmos o Teorema de Pitágoras, na sua forma do espaço
	euclidiano:
	\begin{align*}
		\left| x + y \right|^{2} &= {|x|}^{2} + {|y|}^{2} , x\bot y\\
		\\
		<x,x> &= {|x|}^{2}\\	
		<x+y,x+y> &= \left|x+y\right|^{2}\\
		&=<x,x>+2<x,y>+<y,y>\\
		\\
		<x,y> &= 0 && \text{by x orthogonal to y}\\
		\\
		\left|x+y \right|^{2} &= <x+y,x+y>\\
		&= <x,x>+2<x,y>+<y,y>\\
		&= <x,x>+2*0+<y,y>\\
		&= <x,x> + <y,y>\\
		&= {|x|}^{2} + {|y|}^{2}\\
		\blacksquare
	\end{align*}
		
	\paragraph{Desigualdade de Schwarz}\label{desigualdade-de-schwarz}
	
	\[| < x,y > | \leq \left| x \right||y|\]
	
	Pela propriedade da base do espa?ºo euclidiano ?® poss?¡vel escrever
	
	\[y = \alpha x + z\]
	
	sendo \(x\bot z\) e \(\alpha = \frac{< x,y >}{{|x|}^{2}}\)
	
	Utilizando o Teorema de Pit?ígoras
	
	\[\left| x + y \right|^{2} = {|x|}^{2} + {|y|}^{2}\]
	
	\[{|y|}^{2} = \left| x + y \right|^{2} - {|x|}^{2}\]
	
	Substituindo
	
	\[\left| y \right|^{2} = \left| x + \alpha x + z \right|^{2} - \left| x \right|^{2}\]
	
	\[= \left| x \right|^{2} + \left| \text{ax} \right|^{2} + \left| z \right|^{2} - \left| x \right|^{2}\]
	
	\[= \alpha^{2}\left| x \right|^{2} + {|z|}^{2}\]
	
	Logo
	
	\[\left| y \right|^{2} \geq \alpha^{2}\left| x \right|^{2}\]
	
	Substituindo \(\alpha\)
	
	\[{|y|}^{2} \geq \left( \frac{< x,y >}{\left| x \right|^{2}} \right)^{2}{|x|}^{2}\]
	
	\[\geq \frac{{( < x,y > )}^{2}}{{|x|}^{4}}{|x|}^{2}\]
	
	\[\geq \frac{{( < x,y > )}^{2}}{{|x|}^{4}{|x|}^{2}}{|x|}^{2}\]
	
	logo
	
	\[{|y|}^{2} \geq \ \frac{{( < x,y > )}^{2}}{{|x|}^{2}}\]
	
	\[\left| y \right|^{2}\left| x \right|^{2} \geq {( < x,y > )}^{2}\]
	
	\[\left| y \right|\left| x \right| \geq | < x,y > |\]
	
	Invertendo temos que
	
	\[\left| < x,y > \left| \leq \left| x \right| \right|y \right|\]
	
	\[\]
	
	\paragraph{Norma}\label{norma-1}
	
	Dada a propriedade da norma
	
	\[\left| x + y \right| \leq \left| x \right| + |y|\]
	
	Elevando ambos lados ao quadrado temos:
	
	\[\left| x + y \right|^{2} \leq \left( \left| x \right| + \left| y \right| \right)^{2}\]
	
	Por?®m:
	
	\[{|x + y|}^{2}\]
	
	\[= < x + y,x + y >\]
	
	\[\left| x \right|^{2} + 2 < x,y > + \left| y \right|^{2}\]
	
	Aplicando a Desigualdade de Schwarz:
	
	\[\leq \left| x \right|^{2} + 2\left| x \right|\left| y \right| + {|y|}^{2}\]
	
	\[\left( \left| x \right| + \left| y \right| \right)^{2}\]
	
	\paragraph{Norma Euclidiana}\label{norma-euclidiana}
	
	Caso a fun?º?úo \textbar{}x\textbar{} for declarada como
	
	\[\left| x \right| = \sqrt[2]{x_{1}^{2} + \ldots + x_{n}^{2}}\]
	
	\paragraph{Norma do M?íximo}\label{norma-do-muxe1ximo}
	
	\[\left| x \right| = {|x|}_{M} = max\{\left| x_{'} \right|,\ldots,|x_{n}|\}\]
	
	\paragraph{Norma da Soma}\label{norma-da-soma}
	
	\[\left| x \right| = {|x|}_{S} = \left| x_{1} \right| + \ldots + |x_{n}|\]
	
	\paragraph{Compara?º?úo entre as Normas Euclidianas, M?íximo e
		Soma}\label{comparauxe7uxe3o-entre-as-normas-euclidianas-muxe1ximo-e-soma}
	
	Dada estas defini?º?Áes, podemos provar que:
	
	\[\left| x \right|_{M} \leq \left| x \right| \leq \left| x \right|_{S} \leq n\left| x \right|_{M}\]
	
	A prova pode ser repartida em:
	
	\[\left| x \right|_{M} \leq \left| x \right|\]
	
	\[{|x|}_{M} = \max\left\{ \left| x_{'} \right|,\ldots,\left| x_{n} \right| \right\} = \sqrt[2]{{|x|}_{M}^{2}}\]
	
	\[\left| x \right| = \sqrt[2]{x_{1}^{2} + \ldots + {|x|}_{M}^{2} + \ldots + x_{n}^{2}}\]
	
	Deste modo, necessariamente
	
	\[\sqrt[2]{{|x|}_{M}^{2}} \leq \sqrt[2]{x_{1}^{2} + \ldots + {|x|}_{M}^{2} + \ldots + x_{n}^{2}}\]
	
	A segunda parte ?®:
	
	\[\left| x \right| \leq \left| x \right|_{S}\]
	
	\[\sqrt[2]{x_{1}^{2} + \ldots + x_{n}^{2}} \leq \left| x_{1} \right| + \ldots + |x_{n}|\]
	
	Elevando os dois lados ao quadrado
	
	\[x_{1}^{2} + \ldots + x_{n}^{2} \leq \left( \left| x_{1} \right| + \ldots + |x_{n}| \right)^{2}\]
	
	\[\sum_{i = 1}^{n}x_{i}^{2} \leq \left( \sum_{i = 1}^{n}{|x_{i}|} \right)^{2}\]
	
	Pelo Regra do Quadrado da Soma
	
	\[\left( \sum_{i = 1}^{n}{|x_{i}|} \right)^{2} = \sum_{i = 1}^{n}{|x_{i}|}^{2} + 2\sum_{i < j}^{}{\left| x_{i} \right||x_{j}|}\]
	
	Logo
	
	\[\sum_{i = 1}^{n}x_{i}^{2} \leq \sum_{i = 1}^{n}{|x_{i}|}^{2} + 2\sum_{i < j}^{}{\left| x_{i} \right||x_{j}|}\]
	
	Como:
	
	\[2\sum_{i < j}^{}{\left| x_{i} \right||x_{j}|} \geq 0\]
	
	Ent?úo temos que de fato
	
	\[\left| x \right| \leq \left| x \right|_{S}\]
	
	A terceira parte ?® provar que:
	
	\[\left| x \right|_{S} \leq n\left| x \right|_{M}\]
	
	\[\left| x_{1} \right| + \ldots + \left| x_{n} \right| \leq n(\max\left\{ \left| x_{'} \right|,\ldots,\left| x_{n} \right| \right\})\]
	
	Onde
	
	\[\left| x_{1} \right| + \ldots + \left| x_{n} \right| = \sum_{i = 1}^{n}{|x_{i}|}\]
	
	\[n(\max\left\{ \left| x_{'} \right|,\ldots,\left| x_{n} \right| \right\} = \sum_{i = 1}^{n}{|x_{\max}|}\]
	
	Ou seja
	
	\[\sum_{i = 1}^{n}{|x_{i}|} \leq \sum_{i = 1}^{n}{|x_{\max}|}\]
	
	\[0\  \leq \sum_{i = 1}^{n}\left| x_{\max} \right| - \sum_{i = 1}^{n}{|x_{i}|}\]
	
	\[\sum_{i = 1}^{n}\left( \left| x_{\max} \right| - \left| x_{i} \right| \right) \geq 0\]
	
	Como \(\left| x_{\max} \right| \geq \left| x_{i} \right|\) ent?úo temos
	que a inequa?º?úo ?® sempre verdade.
	
	Com isso temos que:
	
	\[\left\{ \begin{matrix}
	\left| x \right|_{M} \leq \left| x \right| \\
	\left| x \right| \leq \left| x \right|_{S} \\
	\left| x \right|_{S} \leq n\left| x \right|_{M} \\
	\end{matrix} \right.\ \]
	
	O que nos leva a concluir que, de fato,
	
	\[\left| x \right|_{M} \leq \left| x \right| \leq \left| x \right|_{S} \leq n\left| x \right|_{M}\]
	
	\[\]
	
	\paragraph{Propriedade da Norma}\label{propriedade-da-norma}
	
	Outra propriedade da norma ?®
	
	\[\left| \left| x \right| - \left| y \right| \right| \leq \left| x - y \right|\]
	
	Para esta prova s?úo precisos dois passos. Primeiro:
	
	\[x = \left( x - y \right) + y\]
	
	Pelas propriedades b?ísicas da norma
	
	\[\left| x \right| \leq \left| x - y \right| + \left| y \right|\]
	
	\[\left| x \right| - \left| y \right| \leq \left| x - y \right|\]
	
	Tirando a norma dos dois lados, temos que:
	
	\[\left| \left| x \right| - \left| y \right| \right| < \left| \left| x - y \right| \right|\]
	
	\[\left| \left| x \right| - \left| y \right| \right| \leq \left| x - y \right|\]
	
	\[\]
	
	\paragraph{Norma Euclidiana como
		Dist?óncia}\label{norma-euclidiana-como-distuxe2ncia}
	
	Dentro de uma interpreta?º?úo geom?®trica mais cl?íssica, a Norma Euclidiana
	pode ser interpretada como a dist?óncia entre dois pontos.
	
	\subsubsection{Bolas e Conjuntos
		Limitados}\label{bolas-e-conjuntos-limitados}
	
	Uma bola aberta pode ser definida como:
	
	\[B\left( a;r \right) = \left\{ x \in \mathbb{R}^{n};\left| x - a \right| < r \right\}\]
	
	Uma bola fechada pode ser definida como:
	
	\[B\left\lbrack a;r \right\rbrack = \left\{ x \in \mathbb{R}^{n};\left| x - a \right| \leq r \right\}\]
	
	Uma esfera pode ser definida como:
	
	\[S\left\lbrack a;r \right\rbrack = \left\{ x \in \mathbb{R}^{n};\left| x - a \right| = r \right\}\]
	
	De modo que
	
	\[B\left\lbrack a;r \right\rbrack = B(a;r) \cup S\lbrack a;r\rbrack\]
	
	Tamb?®m pode ser chamado de Disco. De particular interesse ?® o disco
	B{[}0;1{]} que ?® chamado de disco unit?írio.
	
	Uma nota?º?úo espec?¡fica existe tamb?®m para a esfera unit?íria:
	
	\[S^{n - 1} = \left\{ x \in \mathbb{R}^{n};\left| x \right| = 1 \right\}\]
	
\end{document}